pretrained: "experiments/fingerspelling_RWTH_26/pose_lstm/epoch=370-step=41922.ckpt"
data:
    modality: "pose"
    train_pipeline:
        dataset:
          _target_: openhands.datasets.isolated.FingerSpellingDataset
          root_dir: "fingerspelling_dataset"
          splits: "train"
          modality: "pose"
          #language_set: ['American','Argentine', 'German', 'Greek', 'Indian', 'Turkish']   # Put languages for glosse set
          #languages: ['American','Argentine', 'German', 'Greek', 'Indian', 'Turkish']      # Put languages for training dataset
          language_set: ['I6' ]   # Put languages for glosse set
          languages: [ 'I6' ]      # Put languages for training dataset


        transforms:
            - PoseSelect:
                preset: mediapipe_holistic_minimal_27
            # - PoseTemporalSubsample:
            #       num_frames: 32
            - CenterAndScaleNormalize:
                reference_points_preset: shoulder_mediapipe_holistic_minimal_27
            - ShearTransform:
                shear_std: 0.1
            - RotatationTransform:
                rotation_std: 0.1
            # - ScaleTransform:
            #     scale_std: 0.2pose.yaml

        dataloader:
            _target_: torch.utils.data.DataLoader
            batch_size: 16
            shuffle: true
            num_workers: 0
            pin_memory: true
            drop_last: true

    valid_pipeline:
        dataset:
            _target_:  openhands.datasets.isolated.fingerspelling.FingerSpellingDataset
            root_dir: "fingerspelling_dataset"
            splits: "train"
            modality: "pose"
            #language_set: ['American','Argentine', 'German', 'Greek', 'Indian', 'Turkish']  # Put languages for glosse set
            language_set: ['I6' ]  # Put languages for glosse set
            languages: ['I6']    # Put languages for testing dataset

        transforms:
            - PoseSelect:
                preset: mediapipe_holistic_minimal_27
            # - PoseTemporalSubsample:
            #       num_frames: 32
            - CenterAndScaleNormalize:
                reference_points_preset: shoulder_mediapipe_holistic_minimal_27

        dataloader:
            _target_: torch.utils.data.DataLoader
            batch_size: 16
            shuffle: false
            num_workers: 0
            pin_memory: true
            drop_last: false



    test_pipeline:
        dataset:
            _target_: openhands.datasets.isolated.fingerspelling.FingerSpellingDataset
            root_dir: 'X:/HandTalk/Handtalk/material'
            #root_dir: 'fingerspelling_dataset/'
            splits: "test"
            modality: "pose"
            #modality: "rgb"
            #language_set: ['American','Argentine', 'German', 'Greek', 'Indian', 'Turkish']  # Put languages for glosse set
            language_set: [ 'I6']  # Put languages for glosse set
            languages: [ 'I6' ]    # Put languages for testing dataset
            inference_mode: true

        transforms:
            - PoseSelect:
                  preset: mediapipe_holistic_minimal_27
            # - PoseTemporalSubsample:
            #       num_frames: 32
            - CenterAndScaleNormalize:
                  reference_points_preset: shoulder_mediapipe_holistic_minimal_27

        dataloader:
            _target_: torch.utils.data.DataLoader
            batch_size: 16
            shuffle: false
            num_workers: 0
            pin_memory: true
            drop_last: false


model:
    encoder:
        type: pose-flattener
        params:
            num_points: 27
            #num_points: 27
    decoder:
        type: rnn
        params:
            rnn_type: LSTM
            hidden_size: 32
            num_layers: 2
            bidirectional: true
            use_attention: true

optim:
    loss: 'CrossEntropyLoss'
    optimizer:
        name: Adam
        params:
            lr: 5e-3

    scheduler:
        name: CosineAnnealingLR
        params:
            last_epoch: -1
            T_max: 10

trainer:
    gpus: 1
    max_epochs: 1000
    #resume_from_checkpoint: "experiments/fingerspelling_RWTH_26/pose_lstm/epoch=370-step=41922.ckpt"

exp_manager:
    create_tensorboard_logger: true
    create_wandb_logger: false
    wandb_logger_kwargs:
        #name: "poselstm_argentine"
        #project: "fingerspelling_latest"
        name: "poselstm_argentine"
        project: "fingerspelling_latest"

    create_checkpoint_callback: true
    checkpoint_callback_params:
        monitor: "val_acc"
        mode: "max"
        save_top_k: 3
        #dirpath: "experiments/fingerspelling_argentine/pose_lstm/"
        dirpath: "experiments/fingerspelling_RWTH_26/pose_lstm/"

    early_stopping_callback: true
    early_stopping_params:
        monitor: "test_acc"
        patience: 100
        verbose: true
        mode: "max"


